---
title: "Executive Briefing: What to Bet On in a World of Constant Change"
author: "Nate Jones"
published: 2025-08-31
url: https://natesnewsletter.substack.com/p/executive-briefing-what-doesnt-change
audience: everyone
scraped_at: 2026-01-05 19:18:58
---

*What doesn’t change? Everything seems like it changes these days.*

*Writing about AI means getting excited about change these days. New models every day now. Updates to the way we think about doing business.*

*And as wild as it is day-to-day, that change is exactly what we’d expect for a new general purpose technology. AI is changing so many things at once—how we work, the technology of work, business strategy, our personal lives—that some studies are finding population-level effects on anxiety driven by AI.*

*So in that world, what doesn’t change?*

*That’s a question I’ve gotten a few times in the past few weeks, and I wanted to address it here, because anchoring in a world of change starts with leadership.*

*But if I’m being honest, I no virtually no leaders who could tell you or me off the top of their heads what won’t change in the next five years. When I ask them that question most stare at me like a deer caught in headlights. They don’t know. We don’t know. And if leaders don’t know, they can’t convey steadiness where it matters at work.*

*That’s what this briefing is for. To find the places where AI doesn't change the fundamentals. To find the places where AI amplifies longterm business trends you can bet on.*

*And to find frameworks in the age of AI that let you leverage those longstanding truths to build something that lasts—even if a new model comes out next week.*

*Today's briefing is different from anything I've written before. I'm going to show you the unchangeable laws that AI operates within. Not generic platitudes—the specific, observable patterns that determine who wins and who falls behind. The bedrock you can build on while everything else churns.*

***What you'll find below:***

1. *Four aspects of durable customer demand you can bet on, regardless of industry*
2. *Three laws of business that outlast tech cycles*
3. *An AI framework across those fundamentals that gives you specific leverage points to build against that won’t shift*
4. *A fun visual ChatGPT artifact that illustrates all this in a way that’s easy to digest, share, and remix for your business specifically*
5. *The Organizational Capabilities That Actually Matter—what to build while everyone else chases models*

*This is the framework I've been building toward for months. Once you see these patterns, you can't unsee them. Every AI announcement, every competitor move, every strategic decision becomes a piece of news that’s easy to slot into its proper place—either as a smart move on the chess board or a waste of effort from someone who doesn’t know what game they’re actually playing.*

*The waves of change will keep coming. But after today, you'll know exactly where the bedrock is.*

> ***This is an Executive Circle briefing**, a Sunday newsletter exclusively for Founding Tier Members. You can learn more via this [60 second video](https://youtu.be/KC3GkEnHR-8) explaining what’s in each tier, and you can change your plan [here](https://support.substack.com/hc/en-us/articles/360044105731-How-do-I-change-my-subscription-plan-on-Substack). Enjoy, and back to regular programming Monday!*

> *PS. Interested in digging in further? This executive briefing is part of an ongoing series I’m doing covering aspects of AI transformation in companies. You can read about how leaders are changing [product strategy](https://natesnewsletter.substack.com/p/executive-briefing-building-products?r=1z4sm5), [driving AI adoption](https://natesnewsletter.substack.com/p/executive-briefing-stop-ai-adoption?r=1z4sm5), and [principles for leading AI culture change](https://natesnewsletter.substack.com/p/ai-change-leadership-9-principles?r=1z4sm5), and [building an AI native business](https://natesnewsletter.substack.com/p/executive-briefing-fire-your-ai-strategy?r=1z4sm5) in issues from previous weeks.*


#### *[Grab the ChatGPT Presentation Canvas for this article here!](https://chatgpt.com/canvas/shared/68b0b1a7b6108191a4bec73978b86e53)*


# Executive Briefing: What to Bet On in a World of Constant Change


## A deep dive on why winning strategies in the age of AI focus on what isn't changing, not what is

Every Monday morning, your leadership team gathers to discuss AI strategy. Someone mentions GPT-5. Another brings up that competitor's flashy AI launch. The board wants to know about your "AI transformation." The consultants pitch their bolt-on AI strategy with a sizzle reel that'll be obsolete in six months. Meanwhile, the fundamentals of your business—the boring, unchanging physics of how value flows to customers—sit ignored in the corner like last year's strategic plan.

Here's what nobody wants to admit: While everyone's chasing the latest model release, the winners are quietly architecting systems based on what *doesn't* change. They understand a simple truth that feels almost heretical in 2025: AI isn't magic. It's a lever. And levers only work when you understand the physics of what you're trying to move. Build on what doesn’t change, and suddenly when and where you need to add AI will get a lot clearer.

This isn't another breathless prediction about AGI or another warning about disruption. This is about something more practical and infinitely more valuable: how to build strategy on bedrock while your competitors build on sand. Because in a world where every headline screams about transformation, the biggest strategic advantage might be understanding what stays exactly the same.


## Learning from Jeff B…

I occasionally get to do this because I worked at Amazon for awhile, so settle in for a Jeff B. story. In the late 1990s, when the internet was going to change everything overnight, Jeff Bezos asked a different question. Not "what's going to change?" but "what's *not* going to change?"

While competitors were trying to predict whether people would shop online for groceries or cars or houses, Bezos identified three things that would never change: customers would never ask for slower delivery, higher prices, or less selection. He built Amazon's entire strategy on these invariants. Every decision, every investment, every innovation served these unchanging desires.

Twenty-seven years later, Amazon is worth $2 trillion. Not because Bezos predicted the internet's evolution, but because he ignored it in favor of constants. When everyone else was building for the internet they imagined, Amazon built for the customer physics that don't change.

The same opportunity exists today with AI. While your competitors chase every new model release, every prompt engineering trick, every fancy demo that gets applause at conferences, you can build on invariants. But first, you need to understand what those invariants actually are. And more importantly, you need to understand how AI amplifies them rather than replaces them.


## Four Things Your Customers Will Never Ask For

Customers have four unchangeable desires. These aren't insights—they're laws of nature, as fundamental as gravity:

**1. Customers will never ask for slower solutions.** Speed isn't just a feature—it's a fundamental force. No customer in history has ever said, "I wish this took longer." They will always choose the faster option when all else is equal. This isn't about impatience; it's about energy conservation. Every moment spent waiting is energy that could be deployed elsewhere.

**2. Customers will never request higher prices.** Given identical value, customers choose cheaper every time. This isn't about being cheap—it's about resource optimization. Money is stored energy, and customers instinctively conserve it. They'll pay more for more value, but they'll never request to pay more for the same value.

**3. Customers will never seek out risk.** Customers de-risk wherever possible. They choose the proven over the experimental, the guaranteed over the probable, the certain over the uncertain. This isn't about being conservative—it's about survival instincts encoded over millennia. Uncertainty requires energy to manage. Certainty doesn't.

**4. Customers will never choose harder access.** Ease of use wins. Always. No customer has ever said, "I wish this was more complicated." They follow the path of least resistance as surely as water flows downhill. This isn't laziness—it's efficiency. Every additional step, every extra click, every moment of confusion is energy that could be saved.

These aren't preferences that might change with generations or demographics. They're physics. Just as electrons follow the path of least resistance, customer behavior flows toward minimum energy expenditure. AI doesn't change these laws—it just changes how dramatically you can satisfy them.

Think about what this means: Every successful product in history has won by delivering on one or more of these invariants better than alternatives. Every failed product has lost by violating them. Every disruption has succeeded by finding a new way to serve them. The strategic question isn't "how do we implement AI?" It's "how do we use AI to deliver 10x improvements on these unchanging customer desires?"


## Informational physics (without formulas)

Here's something they don't teach in business school: Information flows through your organization according to the laws of physics. This isn't metaphorical—it's literal. Every customer interaction, every internal process, every decision follows the path of least resistance. Energy in, value out, following predictable patterns that mirror natural systems.

Consider what this actually means in practice. Your customers adopt products that require the least cognitive energy. Think about the last time you switched from a familiar product to a new one. It wasn't because the new one was marginally better—it was because it was so much better that it overcame your switching resistance. That resistance is measurable, predictable, and follows physical laws.

Your employees follow processes that demand the least effort. This isn't about motivation or engagement—it's about physics. If the right behavior requires more energy than the wrong behavior, the wrong behavior wins. Every time. No amount of training or culture-building overcomes this. You must design systems where the right path is the easy path.

Your data flows through the channels with the least friction. It pools where there's resistance, accelerates where there's clarity, and finds alternate routes when blocked. Every database, every API, every integration follows these patterns. AI doesn't change this—it amplifies it.

Understanding these physics reveals something crucial about where AI actually creates leverage in organizations—and where it doesn't. Because not all organizational dynamics follow the same rules. There's a fundamental distinction that determines whether AI will strengthen or undermine your position, and most companies miss it entirely.


## AI and the authority vs. power dynamic

Consider the difference between authority and power. Authority comes from position—the org chart, the approval chain, the sign-off. It's what the organizational diagram says. Power comes from trust and competence—it's who people actually go to for answers, who they believe, who they follow when things get difficult.

AI can automate authority instantly. It can route approvals, trigger workflows, make decisions based on rules. It can replace entire layers of management whose primary function was to pass information up and down the hierarchy. This is what most companies are doing with AI—automating authority.

But AI cannot create power. It can't build trust. It can't establish competence in the market. It can't make customers believe in you. These things emerge from consistent delivery, from proven expertise, from human relationships built over time.

This distinction matters enormously. Every AI implementation that automates authority without understanding power will fail. The approvals will flow, but the decisions won't be trusted. The workflows will execute, but the outcomes won't be valued. The information will move, but the organization won't.

Meanwhile, every competitor that tries to AI their way to market position without earning trust will discover what you already know: customers can smell inauthenticity from a mile away. An AI can write perfect marketing copy, but it can't create the power that comes from actually solving customer problems consistently over time.

The strategic question for your organization: Is AI strengthening your real power in the market, or just automating empty authority? Are you using it to deepen trust and demonstrate competence, or to paper over fundamental weaknesses? Because your competitors are doing both, and only one strategy survives contact with reality.


## Why compound effects beat moonshots (especially now)

The venture capitalists are wrong. The consultants are wrong. Your board might be wrong. Most of the winners in AI won't be the companies with the biggest, boldest AI initiatives. They’ll be the companies making hundreds of small, compound improvements that accelerate their existing flywheel. Most of the extra ROI will accrue to those steady, consistent bets.

Here's what I see constantly: A company announces a massive AI transformation. They bring in consultants. They create an "AI Center of Excellence." They launch with a sizzle reel that gets coverage in TechCrunch. Six months later, it's quietly shelved. Why? Because they built it with the model and the data integrated to go faster. They cut corners on the architecture to meet the launch date. They optimized for the demo, not the physics.

Meanwhile, their boring competitor is using AI to make their existing customer service 10% faster every month. To make their existing product 5% cheaper to deliver every quarter. To make their existing sales process 15% more certain every cycle. No headlines. No sizzle reels. Just compound improvements that build on each other.

Compound effects are predictable. Big initiatives have binary outcomes—they work or they don't. When you're dealing with technology that changes every six months, betting the company on a massive AI transformation is like building a castle on quicksand during an earthquake.

But compound effects work differently. Each small improvement makes the next one easier. Each reduction in friction accelerates everything downstream. Each AI enhancement that serves your existing customers better strengthens the moat you've already built. More importantly, compound improvements teach your organization how to improve. They build muscle memory. They create systems that get better at getting better.

This is why the "bolt-on AI strategy" your consultants are selling is exactly backward. You don't need an AI strategy. You need to understand your existing strategic advantages and use AI to compound them relentlessly. You need to find every place where you're already creating value and ask, "How can AI make this 10x better for customers?"

These compound effects don't happen randomly. They follow predictable patterns based on how customers actually evaluate and expend energy. Once you understand these patterns, you can design systems that compound in the right direction—toward what customers actually want, not what we think they should want.


## The Energy Customer Matrix: Your New Strategic Framework

When you cross customer invariants with energy physics, something powerful emerges. I call it the Energy Customer Matrix, and it explains more about business success than any framework I've seen.

[![](https://substackcdn.com/image/fetch/$s_!VUs4!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F99a4c345-0757-4792-8629-994924c7d309_654x584.png)](https://substackcdn.com/image/fetch/$s_!VUs4!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F99a4c345-0757-4792-8629-994924c7d309_654x584.png)

Every customer interaction requires energy expenditure. The search, the evaluation, the purchase, the use, the support—all require customer energy. Customers will always choose the solution that requires the least total energy across speed, cost, certainty, and access. This isn't a tendency—it's a law.

But here's what most strategists miss: Customer experiences inherently degrade without consistent energy input. This is entropy, and it's non-negotiable. Your product gets harder to use over time as complexity accumulates. Your service gets slower as processes multiply. Your brand gets fuzzier as messages proliferate.

Without constant energy input to maintain and improve, every customer experience degrades toward a minimum energy state—which is abandonment. Customers leave not in a burst of dissatisfaction but in a gradual drift toward easier alternatives. This is what Amazon Day Two looks like: the slow separation from customers as little things slip, as energy isn't invested, as entropy wins.

AI makes this more critical, not less. That degradation happens faster now. Competitors can exploit gaps quicker. Customers can switch easier. Frankly, bad vibe-coding allows you to add crud to your product faster. The company that was 10% better last year might be 50% worse this year if they haven't been investing energy in the right places.

But here's where the physics gets complicated: customer energy doesn't just flow TO your organization—it flows THROUGH it. And your organization has its own physics that either amplifies or dampens that flow. You can understand customer invariants perfectly, you can map energy expenditure precisely, but if you ignore how your organization actually processes and responds to these forces, you're only seeing half the picture.

This is why so many AI transformations fail despite perfect market analysis and cutting-edge technology. They violate the fundamental laws of how organizations actually change. Not how we wish they'd change, not how consultants say they should change, but how they really change in practice.


## The laws of organizational behavior

Three laws govern this organizational physics, and they're as immutable as the customer invariants we discussed. You can't overcome them, bypass them, or ignore them. You can only design with them or against them. And designing against them is like building a plane that ignores aerodynamics—it might look impressive on the ground, but it's never getting airborne.

The first law explains why most change initiatives fail before they begin:


#### **First Law: Human Nature Creates Predictable Resistance Patterns**

People resist change not because they're stubborn but because change requires energy. And energy is always conserved. Every calorie spent learning a new system is a calorie not spent on existing work. Every moment spent adapting is a moment not spent producing.

But here's the critical insight: Fear acts as a resistance multiplier—it literally dampens the circuit. When people are afraid of AI replacing them, afraid of looking incompetent, afraid of change itself, the resistance doesn't just increase—it compounds. Fear makes the energy required for change exponentially higher.

The most successful AI implementations don't overcome this resistance through force. They don't mandate adoption or threaten consequences. They make the new way so dramatically easier that resistance becomes irrelevant. This is why incremental improvements fail: 20% better isn't enough to overcome resistance. You need 10x. You need the kind of improvement that makes the old way look absurd in retrospect.


#### **Second Law: Energy Flows Through Existing Channels**

Your organization has invisible channels where information and decisions flow. These formed over years, maybe decades. They're carved deep by repetition, by success, by survival. They're not on any org chart, but everyone knows them.

AI doesn't create new channels—it accelerates flow through existing ones. If your channels are broken, AI makes them broken faster. If they're healthy, AI makes them more powerful. If information gets stuck in middle management, AI-powered information will get stuck in the same place, just with more velocity when it finally breaks free.

This is why AI transformations that ignore existing organizational physics fail. You can't AI your way around a broken communication structure. You can't automate your way past trust deficits. You can't algorithm your way through cultural resistance.

The strategic question: Are you trying to use AI to fix broken channels, or to accelerate healthy ones? Because only one of these works.


#### **Third Law: Compound Systems Beat Individual Initiatives**

Everyone focuses on linear growth. The quarterly target. The annual plan. The three-year strategy. These create linear thinking: Hit the number, reset, hit the next number.

But companies that dominate long-term build compounding systems. Each success makes the next success easier. Each improvement strengthens the foundation for the next improvement. Each customer served well makes the next customer easier to serve.

AI supercharges this effect, but only if you design for it. When your AI implementation makes your next AI implementation easier, you're compounding. When your AI improvement teaches your organization how to improve, you're compounding. When your AI investment strengthens your existing advantages, you're compounding.

But when your AI initiative stands alone, when it doesn't build on anything or lead to anything, when it's just a cool demo that doesn't strengthen your core—you're not compounding. You're just spending.

These three laws aren't obstacles—they're design constraints. Just as architects don't fight gravity but use it to create stability, you shouldn't fight organizational physics but use it to create competitive advantage. The question is: how do you actually do that?

The answer isn't in your technology stack or your AI model. It's in building three specific organizational capabilities that work with these laws rather than against them. These aren't nice-to-haves or culture initiatives. They're the mechanical requirements for making AI actually work in the real world of your organization.


## Capabilities of AI-healthy organizations

Understanding the physics is necessary but not sufficient. You need to build three organizational capabilities that work with these physics rather than against them:


#### **1. Structural Tension (Not Conflict)**

Most organizations oscillate between competing priorities—growth versus profitability, innovation versus efficiency, speed versus quality. This oscillation wastes enormous energy and creates confusion. Winners don't oscillate. They create structural tension.

Structural tension requires two things: a crystal-clear future state and a honest assessment of current state. The gap between them creates tension that pulls the organization forward. This isn't the conflict that tears organizations apart—it's the tension that energizes them.

Here's how to create it: Define a future where you deliver 10x on those four unchanging customer desires. Be specific. What does 10x faster look like? 10x cheaper? 10x more certain? 10x easier? Paint it in vivid detail. Make it so clear that everyone can see it, so compelling that everyone wants it.

Then be brutally honest about where you are today. No sugarcoating. No excuses. The gap between your vision and your reality creates structural tension. AI amplifies this tension by making the 10x future actually achievable. Without AI, 10x might be fantasy. With AI, it's a design challenge.

But beware of structural conflict. If your AI vision would fundamentally break your existing organization, you're creating conflict, not tension. Conflict happens when the future state is incompatible with the current state—when achieving one requires destroying the other. That's not transformation; it's destruction. And while sometimes destruction is necessary, it's not what we're talking about here.

Tension energizes. Conflict paralyzes. Know the difference.

Once you have structural tension pulling your organization forward, you face a paradox: AI's power comes from removing friction, but competitive advantage often comes from preserving it.


#### **2. Strategic Friction**

In an age where AI removes friction everywhere, competitive advantage comes from adding friction deliberately. This sounds counterintuitive—aren't we trying to reduce friction? Yes, but selectively.

Make undesirable behaviors hard. Make correct behaviors automatic. This is design, not hope. Amazon doesn't allow PowerPoints—only six-page narratives. That's friction by design. It makes lazy thinking hard and clear thinking easier. The narrative format forces complete thoughts, exposes gaps in logic, and requires real work. The friction serves a purpose.

Where should you add strategic friction? Three places:

First, between AI and customer trust. Any place where AI directly touches customers without human oversight is a place where trust can evaporate instantly. Add friction here. Make it hard for AI to damage relationships. Make it easy for humans to intervene.

Second, between efficiency and innovation. Pure efficiency drives out innovation—it's too risky, too expensive, too uncertain. Add friction to protect innovation. Make it hard to kill experiments too early. Make it easy to try things that might not work.

Third, between speed and quality. AI can move faster than human judgment. That's both its strength and its danger. Add friction where quality matters more than speed. Make it hard to ship garbage. Make it easy to maintain standards.

The key: Strategic friction must be designed, not accidental. Accidental friction is waste. Designed friction is a moat.

But structural tension and strategic friction mean nothing if they don't translate into daily operations. And that translation happens in one specific layer of your organization—the layer everyone wants to eliminate but no one can actually do without.


#### **3. Middle Management Alignment**

Here's the uncomfortable truth no one wants to discuss: Your AI transformation will live or die in middle management. Not in the C-suite where the vision is created. Not on the front lines where the work is done. In the middle, where translation happens.

Middle managers are your transmission system. They translate vision into action, strategy into tactics, principles into practices. If they're not aligned, nothing else matters. You can have the perfect AI strategy, the best technology, unlimited budget—if middle management doesn't buy in, you've got nothing.

But here's what most organizations get wrong: They try to convince middle management that AI won't replace them. This is both dishonest and counterproductive. AI will absolutely replace parts of what middle management does today—the approvals, the reporting, the coordination. That's authority, and AI automates authority.

What AI can't replace is the power that good middle managers wield—the trust they've built, the judgment they exercise, the translation they provide. The question isn't whether AI will change middle management. It's whether your middle managers will use AI to become more powerful or watch their authority get automated away.

Get your middle managers involved early. Not in the "change management" way where you tell them what's happening and ask them to support it. Really involved. Have them identify where AI could make their teams 10x better. Have them design the friction that protects quality. Have them translate the physics into practices.

Because if middle management isn't driving the AI transformation, they're resisting it. And resistance in the transmission system breaks everything.


## Designing for the physics of success

When you understand these principles, system design becomes clear. You're not designing for AI—you're designing for physics, and AI is just making the physics more dramatic.

Design systems where the fastest path is also the safest path. Speed and certainty usually conflict—going fast means making mistakes. But AI can change this. It can make the fast path safe through validation, through testing, through prediction. When customers can move fast without risk, they will.

Design systems where the cheapest option is also the most accessible. Cost and access usually conflict—making something accessible to everyone usually makes it expensive to provide. But AI can change this. It can make personalization cheap, support scalable, customization automatic. When customers can get exactly what they want for less, they will.

Design systems where improvements compound. Every fix should prevent future problems. Every enhancement should enable other enhancements. Every success should make the next success easier. This only works if you're building on physics, not features.


## The questions that matter

Forget "What's our AI strategy?" That's the wrong question, and it leads to bolt-on solutions that satisfy the board but don't serve customers. Here's what to ask instead:

**Instead of:** "How can we implement AI?" **Ask:** "What organizational friction does AI remove, and what new structural tensions does it create?"

**Instead of:** "How do we change our culture for AI?" **Ask:** "What's the current path of least resistance in our business, and how do we redesign it to serve customers better?"

**Instead of:** "How can we grow faster with AI?" **Ask:** "What systems can we build where our next success automatically makes subsequent plays easier?"

**Instead of:** "What will AI change?" **Ask:** "What won't change, and how can AI help us deliver it 10x better?"

**Instead of:** "How do we compete with AI-native startups?" **Ask:** "How do we use our existing power and trust to deliver AI value that startups can't match?"

**Instead of:** "When should we adopt the latest AI model?" **Ask:** "How do we build systems that compound regardless of which model we're using?"

These questions reframe AI from a technology problem to a physics problem. And physics problems have solutions that don't change with the latest release.


## The choice

Your competitors are having prompt engineering workshops. They're launching "AI Centers of Excellence." They're building chatbots and calling it transformation. They're creating sizzle reels for conferences while cutting architectural corners that will haunt them in six months. They're playing with the tools while you can architect the physics.

Some are racing to deploy the newest model, convinced that GPT-5 or Claude 4 or whatever comes next will be their salvation. Others are paralyzed, waiting for the "right" AI strategy to emerge. Both are missing the point.

The companies that dominate the next decade won't be those with the best AI. They'll be those who use AI to deliver exponentially better outcomes on things that never change: speed, price, certainty, and access. They'll be those who understand that AI is a lever, not a strategy. A tool, not a destination.

This isn't about predicting the future. It's about building on principles that don't care what the future brings. The physics of customer behavior hasn't changed since humans started trading shells for food. The laws of organizational energy haven't changed since the first company was formed. AI doesn't change these physics—it just raises the stakes for understanding them.

As I write often these days, the window is open now, but not for long. While others chase the latest model, you can build on bedrock. While they optimize for demos, you can optimize for physics. While they bolt on AI strategies, you can use AI to accelerate the strategies that already work.

But this window won't stay open. As AI capabilities expand, the companies that understand the physics will pull further ahead. The gap between those who compound and those who chase will widen. The difference between building on invariants and building on sand will become impossible to overcome.


## Your next steps

Before your next leadership meeting, before another consultant pitches another transformation, before the board asks again about your AI strategy, do this:

**First, answer three questions:**

1. What gives us real power (not authority) in our market today?
2. Where is the path of least resistance for our customers right now?
3. What would 10x improvement on our unchanging customer desires actually look like?

**Second, identify three places for immediate action:**

1. One process where AI could deliver 10x speed improvement for customers
2. One area where strategic friction would protect quality or trust
3. One compound system you could build where each success enables the next

**Third, align your middle management:** Gather your directors and VPs. Not for a presentation, but for a working session. Have them map the physics of their departments. Where does energy flow? Where does it pool? Where does it leak? Then have them identify where AI could deliver 10x improvements on things that won't change.

Then stop talking about AI strategy. Start talking about using AI to deliver exponential improvements on things that won't change tomorrow, next quarter, or next decade. Start building systems that compound. Start designing for physics, not features.

Because the physics haven't changed. Only the stakes have.

The companies still having AI strategy meetings in 2026 will be the ones who didn't understand this in 2025. The companies dominating their markets will be the ones who stopped chasing AI and started using it to accelerate unchanging principles.

Which one will you be?

[![](https://substackcdn.com/image/fetch/$s_!r8p9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d3b7391-e466-4c6b-a08b-4efd70da40c3_1024x1024.png)](https://substackcdn.com/image/fetch/$s_!r8p9!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7d3b7391-e466-4c6b-a08b-4efd70da40c3_1024x1024.png)
