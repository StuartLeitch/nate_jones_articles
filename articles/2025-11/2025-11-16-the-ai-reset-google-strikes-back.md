---
title: "The AI Reset: Google Strikes Back"
author: "Nate Jones"
published: 2025-11-16
url: https://natesnewsletter.substack.com/p/executive-briefing-the-biggest-ai
audience: everyone
scraped_at: 2026-01-05 19:11:45
---

It’s like a race we can’t look away from. We’re all waiting to see if Gemini 3 beats GPT-5.1. We’re all wondering if ChatGPT will lose the crown.

That’s the wrong question.

The real story isn’t who wins the next benchmark. The real story is that the game we’ve all been playing since 2022 is about to change forever.

I’ve been watching strategic positioning across every major AI lab for months—not just model releases, but capital structures, distribution deals, enterprise contracts, and surface control. What I’m seeing is a structural reset that most people haven’t noticed yet.

Here’s what’s actually happening: while everyone debates which model is best this week (or—let’s be honest—which model they hate most), durable value is migrating away from models entirely. It’s moving to whoever controls the surfaces where people express intent and whoever owns the workflow layer where intelligence gets applied to actual business problems.

The old assumption was simple: pick the best model vendor and ride their sustained technical lead. You would be assured of at least a share of the State of the Art model lead, plus a stable vendor to build from. That is true today if you are on a Google stack, or on an OpenAI stack, or on an Anthropic stack.

But not for long. That assumption is breaking down right now. I think we’re moving to a world where genuine frontier model leadership rotates every 6-12 months. I’m not sure the horse race is going to stay neck-and-neck in 2026.

And I think the first hint of that shift is going to be Gemini 3. The thing to keep in mind, though, is that the reset is structural, not event-driven. So Gemini 3 may be a trigger, but it’s not the underlying driver.

This piece takes you a few months into the future, and walks through where durable value actually lives when models start to trade the #1 position in the benchmarks—and what you should do differently starting now to get ahead.

**Here’s what this article will equip you to do:**

- **For Builders:** Learn where to focus and where to build when there is no permanently winning model—and how to survive when your vendor loses the lead in six months
- **For All of Us:** Understand exactly where to invest your time as models get baked into every surface—and learn why the translator role between what leadership wants and what volatile tools can deliver is about to be in massive demand
- **For Entrepreneurs:** Learn what it will take to design products with real moats when “we use the best model” stops being defensible and OS assistants eat generic use cases
- **For Engineers:** Learn the key skills it will take to thrive when unstable, probabilistic models into systems cause chaos under the surface, and learn the skills you’ll need to deliver for the business in that world
- **For Executives:** Build a multi-vendor strategy that survives when your primary provider gets acquired, pivots, or falls behind—without creating governance chaos
- **For People Leaders:** Understand how model race chaos reshapes the talent landscape, and what you need to do to compete
- **For Investors:** Know where Google, Apple, OpenAI, and Anthropic are actually positioned and which of three futures will determine where you should place your bets

And yes, of course there’s a custom prompt to help you make sense of all this.

Ultimately, whether you’re trying to stay valuable as tools shift under your feet, build something that survives vendor churn, or figure out where to allocate capital when models fragment—this reset changes what works.

I’m convinced we’re on the edge of the biggest shift in AI since 2022. And I want you to be ahead of it.

Let’s dig in.

> ***This is an Executive Circle briefing**, a Sunday newsletter exclusively for Founding Tier Members. You can learn more via this [60 second video](https://youtu.be/KC3GkEnHR-8) explaining what’s in each tier, and you can change your plan [here](https://support.substack.com/hc/en-us/articles/360044105731-How-do-I-change-my-subscription-plan-on-Substack). Enjoy, and back to regular programming Monday!*


## [Grab the AI Reset Prompt and Dig Into the Article](https://www.notion.so/product-templates/Executive-Briefing-AI-Race-Reset-2ad5a2ccb52680968ff0fab68b9f9938?source=copy_link)

This is one of those complex articles that takes thinking and reflection. I built a prompt to help you do just that. Grab the prompt and jump into a conversation about the AI reset and what it means for you and your career, your product, your business.

(And yes, of course, this one is optimized for ChatGPT-5.1, but it will work with any thinking model.)

---


# The AI Reset: Google Strikes Back

We’re entering the most significant strategic reset for AI since ChatGPT launched in 2022. The old assumption—that you could pick the best model vendor and ride their moat to victory—is breaking down. What replaces it is a world where frontier leadership oscillates every few months, distribution consolidates around a handful of OS-level surfaces, and the durable value accrues to whoever owns workflows and governance, not whoever trains the biggest model.

Gemini 3 is the first obvious crack in that old worldview. For the first time since late 2022, a state-of-the-art model will likely emerge from outside OpenAI’s walls, and it may ship as the default intelligence layer for both iOS and Android. That’s significant. But the deeper reset isn’t that Google wins. It’s that from here forward, no single lab will maintain sustained technical dominance, and strategy must adapt to that permanent volatility.

The game is shifting. Models are becoming commodity inputs. Power is migrating to those who control where users speak to AI and how workflows get rebuilt around it. OpenAI’s two-year run as the synonym for AI is ending not because they’ll lose permanently, but because the entire concept of a permanent winner is obsolete.

Here’s how that changes everything for anyone building on, investing in, or competing with AI.


## The Real Battleground: Surfaces, Not Models

The AI landscape is typically analyzed through model benchmarks—who has the smartest reasoning, the fastest inference, the longest context window. That’s insufficient and increasingly irrelevant. Five distinct forces determine who wins, and only one of them is about raw model capability.

**Control of the UX surface is the dominant axis.** Whoever owns what users talk to wins far more than whoever owns the model. This is the central strategic fact, and everything else orbits around it.

Google controls Android with Gemini integrated throughout. Half a billion users already have it as their default, though most don’t realize it. Apple controls iOS but lacks native intelligence, so ChatGPT currently functions as the de facto assistant for iPhone users. That position is more fragile than it appears. Microsoft maintains a stranglehold on Windows and Office through Copilot. Anthropic shows up almost exclusively in applications users choose deliberately—web interfaces, API integrations, developer tools—never as a system-level default.

The surface determines everything downstream. A mediocre model embedded as the OS default beats a superior model buried two taps away. A dumb assistant with frictionless access to your calendar, email, and files delivers more value than a genius that requires you to copy-paste context. Distribution compounds. Defaults win.

**Frontier capability matters, but only as table stakes.** Raw reasoning power, benchmark performance, the leaderboard wars between OpenAI, Google, and Anthropic—these determine whether you’re taken seriously, but they don’t determine whether you win. The top players have traded positions every few months for the past year. The frontier is not stable. It will not stabilize.

What matters is staying close enough to state-of-the-art that users don’t consciously downgrade when they use your surface. If you control the default assistant and your model is 90% as capable as the leader, you win. If you have the best model but users have to install an app and learn new habits, you lose.

**Capital and compute posture separates contenders from pretenders.** Training frontier models costs billions. Sustaining that pace while building products, acquiring users, and maintaining unit economics costs tens of billions. Only a few players can credibly stay in this fight.

OpenAI projects revenue between $12 billion and $20 billion in 2025 but burns $8 to $9 billion annually. They have another $115 billion in planned spend through 2029, with profitability not expected until 2030. Google and Apple effectively have infinite capital from their core businesses. AI is a line item for them, not an existential bet. They can afford to be patient, to make massive bets that don’t pay off, to sustain losses that would kill a startup.

Anthropic reached $5 billion in ARR by mid-2025 and will likely be valued above $300 billion at its next raise. The question is whether their enterprise-focused model—high-trust positioning, premium pricing, safety-first brand—can sustain frontier-scale burn while competitors with different economics flood the market.

**Enterprise penetration and trust determines who captures high-value, recurring revenue.** Consumer users churn. Enterprise customers sign multi-year contracts, integrate deeply into workflows, and pay based on value delivered rather than sticker price.

Anthropic serves over 300,000 businesses with eighty percent of revenue from enterprise, and the largest accounts paying into six figures. The company has built a safety-first brand that resonates in regulated industries—finance, healthcare, legal—where “move fast and break things” is disqualifying. OpenAI has massive usage and high overall ARR, but also serves as the poster child for AGI risk narratives and regulatory scrutiny. Google is a trusted cloud infrastructure vendor with deep relationships and a long history of killing products that don’t scale fast enough. Apple dominates consumer trust but has essentially zero enterprise AI footprint.

**Distribution—the partnerships and platforms that deliver default status—amplifies surface control.** Think of surfaces as the point of contact and distribution as the ecosystem pipes that get you there. You can control a surface without having distribution (Anthropic owns its web interface but lacks consumer channels), or have distribution without controlling the primary surface (Microsoft distributes broadly but doesn’t own mobile OS defaults).

Google has Android, Chrome, and Workspace—direct control of surfaces plus ecosystem distribution. Apple has iOS and macOS but currently routes default intelligence to OpenAI through ChatGPT integration, giving OpenAI distribution without surface ownership. Microsoft has Windows, Office, and Azure. Anthropic has AWS, Google Cloud, and direct API access—strong channels for developers and enterprises, weak channels for consumers.

These five forces interact. Capital buys compute, which enables frontier capability, which justifies distribution partnerships, which deliver default status on key surfaces, which drives enterprise trust and revenue, which funds the next round of capital deployment. But the center of gravity is the surface. Everything else is a means to that end or a consequence of achieving it.


## What the Reset Actually Means

The old game was built on assumptions that no longer hold:

**Before:** You could pick the best model vendor and anchor your strategy around their sustained technical lead. (As much as I’ve been saying for months not to do this, this remains the default stance for most businesses.) OpenAI had the frontier, the brand, the consumer mindshare, and the distribution partnerships. Competitors were playing catch-up. If you were building on AI, you probably built on OpenAI. If you were investing in AI, you probably bet on OpenAI’s ecosystem. If you were an enterprise buyer, you almost certainly evaluated ChatGPT versus alternatives—with Claude gaining ground in recent months.

**After:** It becomes clear to everyone that no one lab maintains sustained technical dominance. The frontier crown may move every six to twelve months—sometimes to OpenAI, sometimes to Google, sometimes to Anthropic, occasionally to an open-weights model that matches 95% of the capability at 5% of the cost. Everyone is about to see that you cannot anchor strategy on any single vendor’s model superiority because that superiority is temporary and unpredictable.

**Before:** Models seemed like the moat. Having a smarter reasoning model seemed like an edge. It’s been assumed too often that distribution will follow capability because users will seek out the best tool.

**After:** Surfaces are the new moat. OS-level defaults—Siri, Gemini, Copilot—will own generic assistance because they’re already where users are. A slightly worse model embedded in the OS beats a slightly better model that requires installation, account creation, and behavior change. The smartest model loses if it’s not on the surface where intent originates.

**Before:** You could treat AI as a software purchase. Pick a vendor, integrate their API, maybe build some wrapper features, and you were done. (Again, I have been begging companies not to think this way, but sadly most do.)

**After:** AI is a workflow rebuilding exercise. The valuable question isn’t “which model?” but “which workflow are we rebuilding, what does the new version look like, and how do we measure whether it’s better?” Models are becoming commodity inputs to that transformation. Governance, data architecture, and process redesign are the hard parts.

**Before:** Capital was a competitive advantage you could deploy to win. Spend more on compute, hire the best researchers, train the biggest models, and you’d build an unassailable lead.

**After:** Capital becomes table stakes for entering the frontier race, not a guarantee of victory. Meta may have already found that out. Google, Microsoft, and Apple can outspend anyone. OpenAI and Anthropic can raise billions on demand, but even their position looks more precarious than the truly big players. Ultimately, what matters is whether you can translate that capital into durable control of surfaces or workflows before competitors do the same.

**Before:** Enterprise buyers could and did standardize on a single AI platform the way they standardized on AWS or Salesforce. That matches standard enterprise modeling of AI as *software* vs. *intelligence*.

**After:** Even less savvy enterprise buyers will be forced to adopt a portfolio strategy. Assume multiple primary vendors—perhaps Anthropic for high-trust workflows, OpenAI for bleeding-edge capability, Google for cost-efficient scale, maybe on-prem models for sensitive data. Enterprises will have to build for vendor churn. This will mean investing a whole lot more in internal abstraction layers. Enterprises will need to treat models more and more as interchangeable contractors, not strategic partners.

If you’ve been reading this newsletter, you won’t be too surprised at any of this.

But the reality is for most businesses, Gemini 3 is simply the first time the old assumptions break in a way that’s obvious to everyone. If Google ships a clearly superior model and Apple licenses it as the default intelligence for iOS, OpenAI loses the halo as the automatic choice. And even if OpenAI regains the lead three months later with GPT-6, the reset has already happened. The idea that any one lab can own the frontier permanently is dead.


## Where the Players Sit in the New Game

**Google is positioned to become OEM intelligence**—the wholesale provider of default smarts for the world’s two largest mobile platforms. Gemini 2.5 Pro is competitive at the frontier already. Gemini 3 will only level up. The company has distribution through Android, Chrome, and Workspace. The key weakness so far has been UX, which has lagged OpenAI and Anthropic.

Assuming Gemini 3 delivers a measurable leap and ships quickly, and if Apple’s reported licensing deal closes, Google transitions from third contender to “Intel Inside” for both iOS and Android. The risk is that Apple wraps Gemini in Apple-branded UX and captures all the consumer brand value while Google becomes invisible infrastructure. The other risk is velocity—OpenAI could maintain distribution advantage through superior product execution even with a technically weaker model.

But if Google solves the UX problem and maintains technical parity, they win by default. They own the surfaces where billions of people will interact with AI, and most of those people will never consciously choose a different assistant.

**Apple is about to prove you can win AI without doing AI research.** Their in-house models are weak. The reported deal to license Gemini for Siri at roughly $1 billion annually is an admission that they’re not going to catch up through internal R&D.

That’s not a problem when you’re sitting on hundreds of billions in cash. It’s a strategy. Apple retains OS integration, identity, payment rails, hardware margins, and the privacy narrative while getting frontier-grade intelligence without frontier-scale capital expenditure. Apple may break the assumption that “to win AI, you must win AI research.” For the right price, labs become vendors. Products become OEMs. And the consumer AI winner is whoever controls the device, not whoever trains the best model.

Of course that dependency creates risk—Apple is now beholden to Google’s roadmap and any associated safety incidents (top of mind post-Claude Code hack). Nevertheless, the Apple deal is a powerful demonstration that surfaces trump models.

**OpenAI faces the most complex strategic position.** They have strong models, dominant consumer mindshare, and roughly $40 billion in raised capital (this number gets bigger every time I sneeze). Projected 2025 revenue sits between $12 billion and $20 billion. They burn $8 to $9 billion a year.

The challenge is that OpenAI is trying to be three different companies simultaneously: a frontier research lab, a consumer product, and an infrastructure provider. Each role has different economics, competitive dynamics, and success metrics. Each role also arguably requires different models.

Meanwhile, OpenAI acquired Johnny Ive’s hardware startup to build a screenless AI device—a bid to own a surface instead of renting someone else’s—but the venture has hit technical and legal snags. They’re not shipping hardware yet, which means capital goes out without distribution coming in.

OpenAI has multiple plausible paths forward. They could secure monopoly-level pricing through sustained technical leadership, though rapid commoditization makes this unlikely. They could achieve massive scale through distribution partnerships—Microsoft, Apple, OEMs, enterprise channels. They could successfully ship hardware and own a new surface category. They could pivot toward becoming primarily an infrastructure and API provider, accepting narrower margins but more stable positioning.

The risk is being caught between strategies—burning billions to stay at a frontier that rotates leadership every few months while lacking the infinite capital of Google and Apple or the enterprise-first positioning of Anthropic. They won’t disappear, but the era of OpenAI as the automatic choice is ending in the next few months, likely with Gemini 3.

**Anthropic is positioned to become the IBM of enterprise AI**—not the flashiest, not the fastest, but the safe, trusted, high-margin provider that conservative buyers standardize on. Revenue scaled to roughly $5 billion in 2025, with projections of $20 to $26 billion in 2026. The base is over 300,000 business customers. Almost all revenue is enterprise, unlike every other frontier lab.

Claude models are near state-of-the-art, efficient, and safe. The ecosystem is strengthening through Model Context Protocol adoption, Claude Skills, and Claude Code. Distribution runs through platforms enterprises already use: AWS, Google Cloud, direct API, SaaS integrations.

Anthropic’s strategy is to let OpenAI and Google fight over consumers while quietly owning the budget lines at the Fortune 500. In a world where frontier capability oscillates and enterprises need multi-vendor strategies, Anthropic becomes the boring, reliable choice—the one you begin to standardize on even if it’s not always the benchmark leader. (Granted, the hack news this week didn’t help their case, but I’m betting they clean that up pretty quick and/or everybody else gets hacked too.)

The risk is balancing frontier-scale investment with enterprise-friendly unit economics. Anthropic must sustain the burn rate required to stay technically competitive while maintaining pricing and margins that work for cost-conscious enterprise buyers. It’s worth noting that incumbent vendors—Salesforce, SAP, ServiceNow—could also become workflow and governance winners by integrating multiple models underneath. Anthropic’s moat is trust and focus, not cost structure or surface ownership. That’s powerful but not invulnerable.


## How This Plays Out: Three Plausible Futures

These aren’t mutually exclusive paths. Elements of all three will likely happen simultaneously in different market segments. The question is which forces dominate.

**Scenario A: Surface Consolidation, Model Fragmentation.** Google becomes OEM intelligence for both iOS and Android. Gemini is the default assistant for billions of users who never consciously choose it. Apple owns the consumer UX layer and the privacy narrative. Google owns the wholesale intelligence contract and the cloud AI sales pitch.

Anthropic carves out enterprise as the safe, trusted, high-margin provider. OpenAI remains a strong player in developer tools, API access, and bleeding-edge research, but loses the “synonym for AI” status over time, and faces ongoing challenges defending its burn rate without owning a major consumer surface.

The winners in this scenario are surface owners (Apple, Google, Microsoft via Copilot) and enterprise governance players (Anthropic, maybe Google Cloud, maybe Microsoft). The losers are single-model SaaS vendors with thin moats who get crushed when OS-level assistants eat generic use cases and enterprise buyers demand multi-model strategies.

**Scenario B: The Device Wars.** Someone—OpenAI, Apple, Google, Meta, or a startup—ships a genuinely compelling AI-native hardware device that becomes the new default surface. Not a phone with an assistant bolted on, but a device designed around continuous ambient intelligence. Glasses, earbuds, a pendant, a screenless voice-first device, something.

Whoever wins this race resets the surface battle. If OpenAI’s hardware play works, they recapture distribution and harvest substantial cash flow through hardware margins and subscriptions. If Apple wins with AirPods or Vision Pro or a new form factor, they further cement their position as the consumer AI interface layer while remaining model-agnostic underneath. If Google or (lol) Meta or Amazon wins, the same logic applies.

The key insight is that this is a surface war, not a model war. The device winner can use any model—Google’s, OpenAI’s, Anthropic’s, an open-weights model. What matters is owning the moment when intent is expressed. The device becomes the new OS. Whoever controls it controls AI access for the next decade.

**Scenario C: Permanent Multi-Model Chaos.** The consumer surface market remains fragmented. Apple can’t execute the Google deal competently and iOS has multiple assistants competing. Android defaults to Gemini but power users switch. Windows has Copilot but everyone uses ChatGPT anyway. No single surface consolidates.

Enterprise buyers explicitly adopt multi-vendor strategies. Perhaps Anthropic for high-trust workflows, OpenAI for maximum capability, Google for cost efficiency, on-prem models for sensitive data. IT departments build internal abstraction layers to route requests across models. Governance tooling becomes the valuable layer, not model access.

Frontier leadership continues to oscillate. OpenAI, Google, Anthropic, open-weights models—they all trade the benchmark crown every few months. No one can sustain a moat through technical superiority alone.

In this scenario, Anthropic likely wins the enterprise game because they’ve built for multi-model from the start. OpenAI struggles unless they pivot to infrastructure or device ownership. Google wins by volume but not by margin. The real winners are companies that own specific workflow surfaces—vertical SaaS players who integrate multiple models behind domain-specific UX. The losers are generalist model providers who can’t differentiate on anything except raw capability—which is no longer a moat.


## Strategic Implications by Role

The reset thesis holds even if Gemini 3 is only 10% better instead of 20% better, or if Apple takes six months instead of three to integrate it. The underlying driver is the strategic position of the players, not the exact timing of individual releases.


### For Individuals

Because frontier models will oscillate and OS-level defaults will handle generic tasks, your durable edge is not “knowing which model is best” but “knowing how to think with volatile tools and design workflows that survive vendor churn.”

Your day-to-day tools will become more opinionated and more embedded. Siri, Gemini, Copilot—they’ll handle email drafts, meeting summaries, basic research, calendar management. The OS defaults will be good enough for most tasks most of the time. Your value is in the work those defaults can’t do: judgment calls, domain-specific problem-solving, workflow design, translating vague executive requests into concrete implementation plans.

The half-life of specific tool skills is dropping fast. Knowing how to prompt GPT-4 well doesn’t transfer cleanly to Gemini or Claude. Mastering one interface doesn’t help when the interface changes or the model underneath swaps. What does transfer is the underlying skill: breaking vague problems into explicit steps, delegating pieces to AI, integrating outputs back into your own reasoning, recognizing when the model is bullshitting versus when it’s genuinely helping.

I keep saying it, but it’s more true now: treat assistants as interchangeable contractors. Use multiple: one for coding, one for writing, one for search, one for structured data work. Test constantly whether a tool is actually helping or just adding steps. The goal is not loyalty to a vendor but efficiency in your workflow.

Become the person who can translate between what leadership wants and what this constantly shifting stack of tools can realistically deliver. That translator role—someone who understands the domain deeply, understands the tools well enough to orchestrate them, and can communicate clearly with both technical and non-technical stakeholders—will be in short supply across every function.


### For Builders

Because OS-level assistants will own generic Q&A and simple automation, and because frontier model leadership will oscillate, your only durable moat is owning a specific workflow surface with differentiated data and multi-model architecture underneath.

You cannot bet on a single model vendor as your core strategy. “We’re the ChatGPT for X” is not a defensible position when ChatGPT itself might not be the frontier leader six months from now. “We’re the AI assistant for Y” is not defensible when Siri and Gemini and Copilot are the default assistants and they’re good enough for generic use cases.

Architect for permanent model volatility. Assume the best model changes every six to twelve months. Build an internal abstraction layer that can route to OpenAI, Gemini, Claude, open-weights models—whatever makes sense for cost, latency, and capability. Your product narrative should never depend on “we use X model” beyond temporary marketing. The model is a commodity input. Your differentiation is elsewhere.

(Again, if you’ve been paying attention this newsletter, this isn’t new. But what’s new is that everybody is about to realize this at once because of Gemini.)

Regardless, pick a surface and own it completely. Decide whether you’re building for email, CRM, EHR, IDE, spreadsheets, ERP, terminal, calendar, phone, or some other specific interface where your users already spend time and express intent. Build deep, opinionated workflows for one or two of those surfaces. Don’t build thin plugins for every surface.

Design as if Siri or Gemini is the top-level orchestrator and your app is the specialized agent it calls for serious work. The OS assistant handles “book me a flight” and “draft an email.” Your product handles “underwrite this mortgage application using our internal guidelines” or “generate a patient care plan following these clinical protocols.” You own the workflow that requires domain expertise, proprietary data, and complex orchestration. The OS assistant owns the handoff.

Differentiate on workflow design plus proprietary data. The defensible stack looks like: frontier model (swappable) → your schema, tools, evals, and guardrails (differentiated) → your customer’s data (irreplaceable) → your domain-specific UX (sticky). The model is the least valuable layer in that stack. Everything else is where margin and moat accumulate.

Financial discipline around AI usage is going to become critical. Assume token costs fall but overall usage explodes. Design features with cost observability from day one. Know which workflows justify spending on frontier models versus mid-tier models versus cheap small models versus local models. Be able to show investors and customers: “Our gross margin is X and improving because we route intelligently across model tiers.” Your unit economics matter far more in a world where infrastructure providers burn tens of billions and eventually need to see returns.


### For Engineers

Because frontier models will change behavior frequently—through version updates, provider swaps, fine-tuning, prompt sensitivity—and because enterprises will use multiple models simultaneously, your core value is turning unstable, probabilistic models into stable, deterministic systems that the business can bet on.

The frontier model itself is not a moat. How you use it, route it, constrain it, evaluate it, and make it reliable is the moat. The stack is getting substantially more complex: retrieval, tool calling, streaming, long-context routing, multi-model orchestration, guardrails, evals, observability, cost controls, security boundaries. This is systems engineering, not prompt engineering.

Specialize in orchestration and infrastructure, not just prompting. Think in terms of request routers, policy layers, tool adapters, memory stores, eval services, feedback loops. Be the person who can go from “we want X capability” to “here is a robust, observable, debuggable pipeline that delivers X with measurable quality, latency, and cost.”

Design for permanent provider churn. Build clean interfaces for LLM calls that can swap between OpenAI, Anthropic, Google, open-weights models, on-prem deployments. Use configuration-driven routing so different customers, use cases, or data sensitivity levels can hit different providers. Build robust fallback behavior for when a provider is down, rate-limited, returns garbage, or changes API contract.

Get exceptionally good at cost-latency-quality tradeoffs. Know when to use frontier models versus mid-tier versus small local models. Know when to use full context versus retrieval-augmented generation. Know when streaming matters versus batch. Be able to show product teams and executives: “We can cut cost 60% with 5% quality degradation, or 20% cost with zero quality loss, or we can improve quality 15% for 40% more cost. Pick your tradeoff.” That capability—making intelligent, measurable tradeoffs visible to decision-makers—becomes critically valuable when model costs are volatile and usage is exploding.

Treat evals and logging as first-class production infrastructure. Always log prompts, outputs (appropriately redacted), latencies, costs, and user corrections. Build or adopt eval frameworks to test for regressions when you swap providers, update prompts, or change routing logic. In a world where model behavior shifts every few weeks, continuous automated testing is the only way to maintain reliability. Manual QA doesn’t scale.

Security and data governance are part of your job now, not someone else’s problem. Understand PII flows, tenant isolation, data residency requirements, and where tokens and logs live. Expect enterprise customers to ask detailed questions: Which providers see our data? Under what terms? How long are prompts and outputs retained? Can we audit what data was used for what purpose? Your ability to answer those questions clearly and implement the corresponding controls determines whether your product is a toy or a tool enterprises can actually deploy.


### For Executives

Because no model vendor will maintain permanent dominance, and because OS-level defaults will own generic productivity while workflow-specific intelligence becomes the battleground, you cannot pick a single winner and be done. Your strategy must assume permanent multi-vendor reality, workflow transformation as the unit of work, and governance as a competitive asset.

Adopt an explicit portfolio vendor strategy. Plan for at least two primary model partners. Don’t centralize all bets on one provider whose roadmap, pricing, and strategic priorities you don’t control. Assume your vendors will change positions, merge, get acquired, or pivot. Architect your internal systems to survive that churn.

Decide explicitly where you lean on OS defaults versus where you build proprietary orchestration. For generic productivity—email drafting, meeting notes, document summarization—let Apple Intelligence or Gemini or Copilot carry the weight. Those are commodity tasks. Your employees will use the OS defaults whether you provision them or not. Don’t fight that.

For core workflows—how you sell, underwrite, diagnose, design, support customers, make credit decisions, generate creative work—invest in your own orchestration and UX on top of swappable models. Those workflows are your differentiation. They’re where margin lives. They’re where you can’t afford to depend entirely on a vendor’s roadmap. Make that line between “commodity productivity” and “strategic workflows” explicit in your strategy documents and your capital allocation.

Frame every AI initiative as workflow transformation, not feature deployment. When someone proposes an AI project, the first questions should be: Which specific workflow are we replatforming? What does the current version look like? What will the new version look like? What metrics will move—cycle time, error rate, throughput, customer satisfaction, revenue per transaction? If the answers are vague, you’re funding demos and experiments, not impact.

AI is not software you buy. It’s a replatforming of how work gets done. The hard parts are change management, process redesign, data architecture, and measuring whether the new workflow is actually better. Model access is the easy part. Most AI initiatives fail not because the model isn’t smart enough but because the workflow wasn’t redesigned and the organization didn’t adopt it.

Treat governance and safety as a strategic asset, not a compliance checkbox. In a multi-model world where different teams use different vendors for different use cases, the valuable capability is not “access to intelligence” but “safe, auditable, cost-controlled orchestration of intelligence across the organization.” Put in place inventories of where models are used. Establish policies on data residency and provider selection. Define clear red-line use cases where AI should not be deployed. Build escalation paths for unexpected behavior or output quality degradation.

This governance infrastructure becomes a competitive advantage when selling to regulated customers or when your own risk and audit functions need assurance. It also becomes cost containment when usage explodes and you need to justify AI spend to the board. “We spent $X million on AI this year and it delivered $Y million in measurable efficiency gains across these five workflows” is a very different conversation than “We gave everyone access to ChatGPT and usage went up.”

Hire for AI-native operators, not just people who can write prompts. The most valuable hires are those who can map your P&L and operations to candidate AI workflows, prioritize those workflows by impact, work with technical teams to get version one live, instrument it for measurement, and train the organization to use it. Titles vary—Head of AI Operations, AI Product Manager, AI Transformation Lead—but the capability is consistent: strategic thinking plus workflow design plus technical literacy plus change management.

Exercise rigorous capital allocation discipline. Do not fund in-house frontier model training unless you have crystal-clear strategic reasons: scale that justifies the economics, proprietary data that creates a defensible moat, regulatory requirements that prohibit external providers, or a business model where the model itself is the product you sell. For everyone else, rent frontier intelligence and own the data, the workflows, and the customer relationships.

Your edge is not having the smartest model. Your edge is turning AI from scattered experiments into a coherent portfolio of workflow transformations with measured ROI, governed under a multi-vendor strategy that survives vendor churn and model volatility.


## What Happens Next

Gemini 3 proves no one can win permanently. The crown is probably going to keep moving—OpenAI had it for two years, Google might have it for six months, Anthropic or another lab might take it next. The underlying shift is structural, not event-driven.

Surfaces will consolidate while models fragment. In the plausible Gemini-Apple scenario, Google powers both iOS and Android by default in consumer scenarios, and Microsoft owns Windows and Office through Copilot. Those surfaces don’t churn the way models do. Once embedded in the OS, defaults win through inertia. A dumber model with frictionless access to your calendar, email, and files beats a smarter model that requires you to context-switch.

Workflows and governance become the enterprise battleground. The valuable capability is not “access to a smart model” but “safe, auditable, cost-controlled orchestration across multiple smart models.” Anthropic is building this. So are incumbent vendors like Salesforce and ServiceNow, integrating multiple models behind workflow-specific interfaces. Whoever makes multi-model governance easy and compliant captures enterprise budgets even without winning benchmarks.

Capital is table stakes for playing the frontier game, not winning it. Google, Microsoft, and Apple can outspend anyone indefinitely. The constraint is no longer “can you afford to train frontier models?” but “can you translate frontier capability into durable control of surfaces or workflows before someone else does?”

We’re entering an era of permanent volatility in model capability and permanent consolidation in surface control. As I’ve been arguing for months, the winners will be those who built for that reality before it became obvious. Gemini 3 is simply the moment when it becomes obvious.

[![](https://substackcdn.com/image/fetch/$s_!L_KI!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff2bf3cf-cb8b-4340-8c85-55d6f4069dbd_1024x1024.png)](https://substackcdn.com/image/fetch/$s_!L_KI!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fff2bf3cf-cb8b-4340-8c85-55d6f4069dbd_1024x1024.png)
