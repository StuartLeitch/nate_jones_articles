---
title: "Getting Past Insight: A Career Handbook for When Intelligence Is Cheap"
author: "Nate Jones"
published: 2025-11-10
url: https://natesnewsletter.substack.com/p/in-the-age-of-ai-good-judgement-is
audience: everyone
scraped_at: 2026-01-05 19:12:11
---

Teaching good judgement is so hard we mostly prefer to avoid it.

For decades in tech the accepted way to learn one of the most important skills in the game was to just hang out around a Principal of some sort (Engineer, maybe, or a very senior Product person, or a Director in another job area).

Somehow, through osmosis, we were all supposed to learn good judgement.

And when good judgement wasn’t the bottleneck, that was ok.

But now it is. Now intelligence is cheap, and as a result good judgement is 100x more valuable.

In this new world, the old way of learning by osmosis just won’t cut it.

Executives I talk to are literally making hire/fire decisions now based on the perceived ability of employees to exercise good judgment in the age of AI.

They know intelligence is getting cheaper thanks to AI. But they have a problem: finding people who have that elusive skill: good judgement.

**Good judgment is knowing what matters.**

It’s distinguishing signal from noise. Seeing second-order effects. Understanding when rules apply and when they don’t.

In the AI context: knowing when to trust output vs verify. Recognizing that “AI can do this” doesn’t mean “we should have AI do this.” Seeing the difference between demos and production-ready systems.

It’s pattern recognition plus wisdom about tradeoffs. You can have high intelligence and terrible judgment.

Good judgment is what makes someone say “wait, let’s think about this differently” when everyone else is nodding along.

The truth is that good judgement is becoming one of THE bottlenecks in the age of AI. One of those things only humans can do.

The problem is no one is teaching it.

I wrote this guide to help solve that. I want you to walk away with a very clear sense of one of the most valuable skill sets in the world right now.

I believe in specifics when teaching skills, so we’re going to get into ten components of excellent judgement:

1. **How to find real bottlenecks** instead of surface problems—the scarcity principle that shows where value migrates.
2. **Methods for reusing patterns without overgeneralizing**—pattern recognition crossed with context discrimination.
3. **The framework for possible versus possible now**—thinking in constraints instead of paralyzing with analysis.
4. **Sequencing strategies that build momentum**—ordering bets to create proof before resistance mounts.
5. **The deprioritization discipline**—explicitly defending what you’re NOT doing to create disproportionate focus.
6. **Calibration through feedback loops**—how judgment compounds when you learn from what worked and failed.
7. **Social graph mapping**—planning conviction moments instead of hoping stakeholders align.
8. **Ownership frameworks**—signaling accountability by stating what you’ll do if you’re wrong.
9. **Transparent reasoning**—making your trade-offs visible instead of just showing polished outputs.
10. **System design for encoding judgment**—shifting from personal heroics to organizational capability.

Because it’s me, I’ve also built a very comprehensive prompt that assesses your judgment across all ten principles and gives you a 30-day action plan.

What you won’t find here is abstract theory. You’ll get specific, demonstrable capabilities based on what I’m seeing in closed-door conversations about who gets promoted, hired, and left behind.

The shift is already happening. Intelligence is cheap. Judgment is scarce.

Let’s dig in and figure out how to learn and demonstrate one of the most valuable skills on the planet today.


## [Grab the Judgement in the Age of AI Prompt](https://www.notion.so/product-templates/Good-Judgement-in-the-Age-of-AI-Prompt-2a75a2ccb52680c09effd6408c61951b?source=copy_link)

Before we dive in, I’ve built a prompt to help you assess your own judgment skills and identify where you need to improve. Good judgment isn’t one skill—it’s a set of capabilities like finding bottlenecks, sequencing for momentum, defending what you’re NOT doing, and owning consequences when you’re wrong.

This prompt walks you through a structured self-assessment on all the key dimensions of judgment, then analyzes your answers to identify your weakest areas with evidence from your own work. It delivers a focused 30-day action plan to improve the single skill that will make the biggest difference for you right now.

The prompt is designed to push past vague self-evaluation and force you to see where you actually need to grow—it won’t let you hand-wave. Copy it into ChatGPT or Claude and let it interrogate you. You’ll get honest feedback on where your judgment is strong and where it’s costing you.

---


# Getting Past Insight: A Career Handbook for When Intelligence Is Cheap


## The Problem Nobody’s Named Yet

If you’re someone who generates insights for a living - whether as an external consultant, an internal strategist, or just the person in your organization who “gets AI” - you’re facing a problem that most people haven’t articulated yet: your core skill just became abundant.

This isn’t about AI “coming for your job” in the obvious sense. It’s more subtle and more interesting than that. For the past few decades, the ability to synthesize information into actionable insights has been genuinely scarce. It required time, expertise, pattern recognition, and analytical horsepower that most people and organizations didn’t have. If you could do it well, you had a valuable skill.

That scarcity is ending. Not because AI can think better than you, but because the cost of intelligence has collapsed to essentially zero. What used to take a team of consultants three weeks and $50,000 - gathering information, analyzing it, identifying patterns, generating recommendations - can now happen in an afternoon for twenty dollars.

The question is: what do you do when your primary value proposition becomes abundant?


## The Non-Obvious Framework

There’s an economic framework that explains what’s happening, though it comes from an unexpected place. In a recent essay, Alex Danco at a16z laid out [two related phenomena: Jevons Paradox and the Baumol Effect](https://substack.com/home/post/p-177698479).

Jevons Paradox says that when something becomes radically more efficient, we don’t use less of it - we use vastly more. When coal production became efficient in the 1800s, England didn’t use less coal; it used exponentially more. When computing became a billion times cheaper, we didn’t buy fewer computers; we embedded them in everything from thermostats to shipping tags.

The Baumol Effect says that when productivity explodes in one sector, wages rise in other sectors that didn’t become more productive - because all jobs compete in the same labor market. If you can make $150/hour installing HVAC in data centers, you won’t accept less for residential HVAC work, even though that work hasn’t changed at all.

Danco applies this to the AI boom: some goods and services will become radically cheaper (Jevons), while others will become more expensive even though they haven’t improved (Baumol). His example: you can buy a flatscreen TV cheaper than hiring someone to fix drywall, because manufacturing got productive but handyman work didn’t.

But there’s a third implication he doesn’t explore explicitly, and it’s the one that matters for anyone who works with intelligence:

**When intelligence generation becomes cheap (Jevons), the human work around intelligence becomes expensive (Baumol).**

The insight generation itself is the flatscreen TV - abundant and cheap. The human judgment, implementation, and navigation around that insight is the drywall repair - scarce and expensive.

This applies whether you’re an external consultant or an internal AI enthusiast. In both cases, you’re dealing with the same fundamental shift: getting TO insight is now trivial. Getting FROM insight to outcome is where all the value lives.


## What This Means Practically

Let’s be concrete about what changed and what didn’t.

**What became cheap:**

- Gathering information (AI can read thousands of documents instantly)
- Running analysis (any framework, any comparison, any synthesis)
- Generating insights (AI can produce dozens of plausible recommendations)
- Drafting communications (decks, memos, reports)

**What stayed expensive:**

- Knowing which insights actually matter given real constraints
- Building conviction that a recommendation is right despite uncertainty
- Navigating organizational politics to get things implemented
- Being present for the messy work of change
- Taking responsibility when things go wrong

If you’ve been selling the first list (insight generation), you’re in trouble. If you can deliver the second list (insight to outcome), you’re newly valuable.

The shift is from being an intelligence generator to being an intelligence navigator. You’re not the person who produces the insight. You’re the person who knows which insight matters, why it matters now, and how to make it real.


## The Curation Practice

The first skill to develop is insight triage. When you can generate forty insights in an hour, the skill isn’t generation - it’s curation.

Most people don’t realize how much implied curation happened in the old model. When analysis took weeks and cost tens of thousands of dollars, you only got a handful of insights at the end. Those insights felt valuable partly because of the cost signal. The selection had already happened, hidden inside the expensive process.

Now you can generate comprehensive options in minutes. The curation has to become explicit.

This means learning to evaluate insights not for analytical rigor (AI is often better at that than humans) but for implementability. Which insights are:

- Politically viable given existing stakeholder dynamics
- Economically meaningful given the business model
- Actually executable given organizational capacity
- Correctly timed given current priorities and constraints

The valuable consultant - internal or external - is the one who can say: “I generated forty insights. Here are the three that matter for you specifically, here’s why, and here are the five I’m explicitly deprioritizing with explanations.”

The deprioritization is as important as the prioritization. Anyone can say “do these three things.” Knowing what NOT to do, and why, is the judgment.

For external consultants, this means changing how you present work. Instead of hiding the exploratory process and presenting three polished recommendations (which implies these were the only options), show more of the option space and explain your filtering logic. Your value is in the filter, not the generation.

For internal people, this means resisting the urge to share every interesting thing AI helped you discover. Pick the one or two insights that are actually implementable in your context, and go deep on making those real. Your value is in understanding the constraints that outsiders can’t see.


## The Judgment Practice

The second skill is making your judgment visible and credible.

In the old model, judgment was wrapped inside analytical rigor. “We did extensive analysis” implied “therefore our recommendations are sound.” The work product - the models, the data, the frameworks - was proof of quality thinking.

That signal is broken. Anyone can produce extensive analysis now. What matters is judgment that goes beyond the data: pattern recognition from adjacent contexts, anticipation of second-order effects, intuition about what will actually work in this specific situation.

This requires separating “what the data says” from “what I think it means” in your recommendations. Be explicit about which parts are analytically derived and which parts are judgment calls based on experience or pattern matching from other contexts.

For external consultants, this means building and maintaining a judgment track record. You need to be right about your calls over time, and you need to be correctly calibrated about your confidence. When you’re certain, say so and be right. When you’re uncertain, say that too and explain the considerations. The credibility comes from the calibration, not from pretending to be certain about everything.

For internal people, the challenge is different. You don’t have a portfolio of past clients to point to. Instead, you need to build judgment credibility through small, verifiable wins. Start with low-stakes predictions or recommendations where you can demonstrate your judgment, then scale up as your track record grows. “I said we should do X for these reasons, we did it, here’s what happened” is worth more than “I have good instincts.”

The key insight: Your judgment is valuable precisely because you’ve seen patterns across multiple contexts that don’t exist in any single dataset. An AI trained on a company’s data can tell you what that data implies. You can tell them what it means based on seeing similar patterns play out differently in different environments. That’s non-commodifiable, at least for now.


## The Implementation Practice

The third skill is enabling actual change, which is where most AI-generated insights die.

Here’s what’s new: In the old model, by the time you got to recommendations, the client or organization had been on a journey with you. Months of data gathering, interviews, workshops, analysis. The insight generation process itself was the change management process. People were bought in because they’d invested in getting there.

Now you can skip straight to insight in days or hours. But the organization hasn’t been on the journey. They haven’t built conviction. The change management didn’t happen. So even though you got to the answer faster, implementation might actually be harder.

This means the consulting motion changes. Less time on analysis, more time on making change possible.

For external consultants, this looks like shifting from “insight delivery” to “implementation partnership.” You might generate the insights in week one, then spend weeks two through twelve helping the organization actually act on them. The billable work isn’t the analysis anymore - it’s the navigation, the piloting, the iteration, the training, the measurement.

For internal people, this is actually where you have an advantage over external consultants. You can be present for the messy middle. You can iterate, fix things that break, adjust as you learn, and maintain momentum over months. The implementation practice for you is about building systems that work without you. If people need you to run it, it doesn’t scale. You need to create self-service workflows, clear documentation, simple interfaces, and training that enables others to maintain what you’ve built.

Both need to get better at rapid validation - stress-testing insights quickly rather than perfecting analysis slowly. Both need to focus on measurement that shows business outcomes, not technical metrics. And both need to recognize that the hard part isn’t figuring out what to do anymore. The hard part is getting it done.


## Where the Paths Diverge

While the core insight applies to both external and internal consultants, the value capture mechanisms are completely different.

**External consultants** face a pricing problem. If insight generation is cheap, how do you justify consultant fees? The answer is to explicitly price and sell implementation, not analysis. Your proposals should spend less time on “here’s our analytical approach” and more time on “here’s how we’ll ensure this actually gets done.” The deliverable isn’t the deck. It’s the changed state of the organization.

You also face a positioning problem. Being “the AI strategy consultant” puts you in a commodifying category. Being “the person who implements AI transformations in [specific domain]” is more defensible. Narrow your domain, go deep on implementation, and build case studies around outcomes rather than insights.

**Internal AI enthusiasts** face a visibility problem. Even if you’re delivering value, it doesn’t automatically translate into career advancement unless the right people notice. This means being strategic about what you work on (high visibility, clear metrics, low political risk) and how you communicate outcomes (business impact, not technical achievement).

You also face a scope problem. You could help everyone with their prompts, becoming the internal AI help desk. That’s low leverage. Better to build repeatable systems that deliver outcomes without requiring your ongoing involvement. Turn one-off help into documented playbooks, office hours, and self-service tools. Your goal is to reduce help requests over time while increasing impact.

The internal advantage is compounding. External consultants move from project to project. You can build systems that generate value quarter after quarter. That compounds into career capital in ways that project work doesn’t.


## The Transition Play

If you’re reading this and thinking “I need to change how I work,” here’s the practical sequence:

First, audit your current work. How much time goes to insight generation versus insight implementation? If it’s more than 30% generation, you’re probably over-indexed on the commodifying part.

Second, pick one problem - ideally something painful, visible, and measurable - where you can deliver a complete outcome, not just an insight. For external consultants, this might mean doing a small project where the deliverable is “working system” rather than “strategic recommendations.” For internal people, this means finding something broken in your domain and fixing it completely, with documentation and handoff.

Third, document not just what you did but how you thought about it. What made this problem worth solving? How did you prioritize it against other options? What were the constraints that shaped your approach? What would you do differently next time? This becomes your demonstration of judgment, not just execution.

Fourth, make it visible to the people who matter. For external consultants, this is case studies and positioning. For internal people, this is communicating outcomes up and across the organization - not “I built a thing” but “here’s what changed and here’s the business impact.”

Fifth, repeat. One outcome doesn’t make you an implementation specialist. Three starts to look like a pattern. Five is a practice.


## What This Enables

The opportunity here isn’t just defensive (protecting your value as insight generation commodifies). It’s offensive. Most organizations are drowning in insights they don’t act on. The gap between “what we should do” and “what we’re actually doing” has never been wider, precisely because generating the “should do” is now so cheap.

If you can bridge that gap reliably - if you can be the person who not only sees what should happen but makes it happen - you’re solving the constraint that matters most.

For external consultants, this means building a practice around outcomes rather than analysis. You’re not selling insight; you’re selling changed organizational states. That’s harder to deliver but much more valuable and much harder to commodify.

For internal people, this means converting AI fluency into career capital by being the person who ships things that matter. Not the person who knows about AI, but the person who delivers outcomes using whatever tools make sense.

The underlying bet is this: Intelligence became cheap, which means the bottleneck moved. The new bottleneck is implementation - judgment, navigation, execution, presence. That’s where the value is now.

Get good at that, and you’re not competing with AI. You’re leveraging AI to deliver what actually matters: outcomes.

[![](https://substackcdn.com/image/fetch/$s_!jGpu!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ef6634d-370c-4298-921d-41311a14cd27_1024x1024.png)](https://substackcdn.com/image/fetch/$s_!jGpu!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ef6634d-370c-4298-921d-41311a14cd27_1024x1024.png)
