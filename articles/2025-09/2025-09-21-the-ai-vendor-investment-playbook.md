---
title: "The AI Vendor Investment Playbook"
author: "Nate Jones"
published: 2025-09-21
url: https://natesnewsletter.substack.com/p/executive-briefing-how-to-buy-the
audience: everyone
scraped_at: 2026-01-05 19:17:19
---

Yes, $1.2 million dollars. That’s the average amount companies are spending on AI solutions this year.

And it’s only going up. All while executives struggle to make sense of the AI they are supposed to purchase.

It’s a recipe for scammers and (at best) regretted purchase. In fact, bad purchases were cited by many execs during those infamous MIT interviews that led to the “95% of AI Projects Fail” headline.

But how do you avoid making a bad AI purchase? What’s different about AI relative to other software purchases? What does a healthy investment cycle for AI look like? What does due diligence look like for AI solutions?

That’s what this post is for.

If you’ve ever felt caught between the demand to deploy AI and confusion around how to assess which AI to purchase, this briefing is for you!

I’ll show you how to take an active stance in the AI purchase cycle with specific questions. I’ll walk through AI-specific due diligence practices and exercises designed to catch scammers, and I’ll equip you so you feel confident you can make the right AI investment decision for the business.

Yes, you ***can*** make the right call even if you’re still ramping on AI yourself. You don’t need to delegate this to the IT department (in fact, that’s mistake number one).

Catching vendors who are (at best) a bad fit is absolutely possible, and it’s critical if you want to complete your AI transition.

One bad purchase can lead to months of delay, millions down the drain, free momentum for competitors, and bad morale on your team.

It’s serious stuff, and I’ve seen entire companies emerge in 2025 who do nothing but clean up the AI messes bad vendors leave. It’s a whole cottage industry at this point because there are so many shady vendors rushing into the gold rush with poor AI solutions. Don’t end up a victim!

Take ownership and run a proper AI due diligence process and you’ll be much more likely to make an un-regretted AI investment that actually moves you forward.

This playbook shows you exactly how to make the right AI vendor bet so you can get back to focusing on the rest of the AI transformation challenge (see more articles on that below).

Let’s dive in!

> ***This is an Executive Circle briefing**, a Sunday newsletter exclusively for Founding Tier Members. You can learn more via this [60 second video](https://youtu.be/KC3GkEnHR-8) explaining what’s in each tier, and you can change your plan [here](https://support.substack.com/hc/en-us/articles/360044105731-How-do-I-change-my-subscription-plan-on-Substack). Enjoy, and back to regular programming Monday!*

> *PS. Interested in digging in further? This executive briefing is part of an ongoing series I’m doing covering aspects of AI transformation in companies. You can read about how leaders are changing [product strategy](https://natesnewsletter.substack.com/p/executive-briefing-building-products?r=1z4sm5), [driving AI adoption](https://natesnewsletter.substack.com/p/executive-briefing-stop-ai-adoption?r=1z4sm5), and [principles for leading AI culture change](https://natesnewsletter.substack.com/p/ai-change-leadership-9-principles?r=1z4sm5), and [building an AI native business](https://natesnewsletter.substack.com/p/executive-briefing-fire-your-ai-strategy?r=1z4sm5) in issues from previous weeks.*


# The AI Vendor Investment Playbook


## The $400 AI scam in plain sight

Most companies have a $400,000 AI scam hiding in plain sight. The average company spends $1.2 million on AI. They're increasing budgets. And the average contract is $400,000 for an AI vendor.

When you factor in that 88% of executives are increasing their AI budgets, but just 8% feel fluent, you have a recipe for scams. You have vendors who misrepresent what they can do, misrepresent their AI solutions, and then you get AI mess and you have to pay more AI consultants to bail you out.

MD Anderson Cancer Center lost $62 million on IBM Watson for Oncology. The U.S. Department of Labor's unemployment claims AI wrongly denied thousands of legitimate claims. A Hong Kong bank lost $25 million to deepfake scammers posing as executives on video calls.

These aren't small companies making rookie mistakes. They're sophisticated organizations that got burned because they let vendors control the narrative.

That infamous MIT study that found 95% of enterprise AI pilots fail to reach production? The main reason isn't technical limitations. It's lack of business alignment and poor procurement discipline. AI disasters in 2024-2025 erased billions in shareholder value, not just operational budgets.

It doesn’t have to be this way.

Even if you're a non-technical executive, you can expose vendors who don't know what they're doing. The tools are simpler than you think.


## Case Studies in Failure

Let me walk you through exactly where procurement broke down at MD Anderson and the Department of Labor. These aren't abstract lessons—they're multimillion-dollar failures that map directly to what's probably happening in your vendor meetings right now.


### MD Anderson's $62 Million Watson Disaster

IBM Watson for Oncology was supposed to revolutionize cancer treatment. MD Anderson invested $62 million based on IBM's demos showing Watson outperforming humans in treatment selection.

Watson was piloted on handpicked, well-labeled patient records. Not on the patchy, inconsistent, multi-system data that defined daily workflow at MD Anderson. The vendor demos used IBM's proprietary test data, avoiding the true messiness of hospital information systems.

Clinical workflows at MD Anderson are complex, with exceptions, interdisciplinary overrides, and evolving care standards. Watson's core logic didn't map onto this business reality. Its recommendations often missed crucial context or selected drugs unavailable locally.

The contract lacked requirements for user confidence scores, integration with local systems, or quantitative metrics on operational improvement. No performance rollback. No penalty language. When staff found Watson's recommendations confusing or misleading, most oncologists defaulted back to manual review. ROI evaporated.

After years and tens of millions spent, MD Anderson shuttered the project. IBM later exited Watson Health entirely.


### The Department of Labor's Claims Processing Failure

The Department of Labor deployed an AI workflow for unemployment claims meant to revolutionize benefit delivery and fraud detection. A respected federal IT supplier showcased the system in controlled pilots. All sandbox tests passed. Accuracy and fraud-detection rates exceeded legacy benchmarks.

The vendor controlled testing. They used sanitized datasets—clean records, standardized claimant information, perfect legacy feeds. This masked the chaos of true state-level data integration: conflicting formats, gap-filled records, and legacy system errors.

Executives accepted generic assurances like "high accuracy" and "seamless integration." The contracts lacked pass/fail criteria for core business outcomes. No requirement to prove the system on the agency's actual messy data.

In production, the AI made thousands of erroneous denials and flagged legitimate claims as fraudulent. The integration failed to process at least a dozen legacy data streams. The system had to be pulled. They reverted to manual operations and incurred millions in emergency rescue spend. Congressional scrutiny followed.


### What went wrong for both?

Both disasters started the same way. Polished vendor demos on sanitized data. Executives delegating technical vetting. Contracts without business performance criteria. No testing on real, messy production data.

Both organizations had technical teams, procurement processes, and board oversight. What they didn't have was executive ownership of AI evaluation.

The downstream costs multiplied. Emergency consulting. System rescue operations. Reputational damage. Public embarrassment. Congressional hearings. All preventable if executives had taken control of the procurement process.


## Executive fluency gaps enable vendor scams

When only 8% of leaders feel they have AI fluency, you have to commit to not outsource AI evaluation. Strategic AI buying requires business context as much as or more than IT department sign-off. IT can't sign off on this—this is a business decision.

MD Anderson delegated Watson's evaluation to technical teams who accepted IBM's claims about treatment recommendation accuracy. They never forced Watson to work with their actual messy patient records or prove it could recommend drugs actually available in their formulary.

The Department of Labor let vendor project managers own integration, assuming sandbox success would translate to real claims processing. Nobody asked what happens when the system flags a legitimate claim as fraudulent.

In so many cases when this goes wrong, it's the leader who delegated responsibility for something they did not know well and could not drive accountability on correctly. AI is too big a business decision to delegate.


## The buyer’s toolkit

First, ask better questions! Vendors thrive on hype. Don’t let them.

The solution starts with displacing the vendor demo talk track. Vendors like to own the metrics, the narrative, the toolbox. You need to take control to get the evaluation done properly.

The best way to expose vendor weaknesses is through strategic prompting to push vendors out of their comfort zone during demos. (Yes, you can prompt people like LLMs.) Here's your formula:

> *As context, in our business, we are dealing with [describe a messy business reality].*
>
> *So I have a task for you: please show me how your AI handles [describe the edge case that breaks most systems].*
>
> *Don’t just tell me you can—I need to see you do it live with our data in front of us and explain each step as you go.*

Example scripts:

- Show me how your system handles an angry customer using profanity and demanding to speak to the manager, with our actual complaint data.
- Process a batch of invoices where 30% have data entry errors, missing fields, or unusual formatting.
- Analyze this contract where key terms are buried in appendices and cross-referenced across five different documents.

Push the edges. Vendors prepare demos with clean data, but your ecosystem isn't clean.


### Testing Vendor Claims

Vendor AI claims are especially suspect, because AI models are probabilistic.

When the vendor claims 99% accuracy, that means one time out of 100 something doesn't work. What happens that one time? Where does it break? How did they measure it?

Watson claimed superior treatment selection. MD Anderson never asked: "Show us the 1% where you're wrong. What happens to those patients?"

When the vendor claims sub-second response time—under what load? When they claim enterprise-grade security, ask for their SOC 2 report. A Hong Kong bank lost $25 million to deepfake fraud because they didn't validate security claims. When they claim seamless integration, demand they demo the integration with your existing systems. Live.


### Hot Spot: Integrations

Integration is where value gets snagged, because AI systems require deep interoperability to work well.

Ask about data flow:

- Walk me through exactly how data gets from our systems to your AI and back.
- What happens when our data format changes?
- Show me your error handling when our systems are down.

Dig in on security:

- Where does our data live during processing?
- Who at your company can access it?
- What's your process if there's a data breach?
- What happens if the model maker’s ToS changes?
- What happens if I want to switch models?

Don’t forget change management:

- How will your updates affect our workflows?
- What happens to our customization when you release new versions?
- Who is responsible when your changes break our integrations?
- When smarter models release, how will we get those?
- What does ongoing training look like?
- What’s the ramp time for specific teams across my business, why?

The Department of Labor never asked these questions. Their AI couldn't process a dozen legacy data streams. Watson's recommendations didn't integrate with MD Anderson's clinical workflows. Both learned after signing contracts. And that’s too late.


## But don’t stop at questions—get into the sandbox

Traditional vendor evaluations are too easy for high-stakes AI. You need to be in charge of the testing environment, and you need to see how AI edge cases actually emerge on real data. Your data.

Sit down with your IT team and everyone who will use this solution. Prepare three to five killer scenarios that will break most vendors. Get your messiest data ready. Define what acceptable success looks like.

Watch everything live. Watch the vendor struggle with your data and your use cases. Even if you're non-technical, sit there and watch. You'll see what your teams will go through. You'll know if this vendor can be a real partner.

The psychological hurdle is real. You might feel unfamiliar with technical evaluation. Asking "naive" questions and controlling the demo is not a weakness—it's a board-level skill when the market is full of hype and fraud.

Don’t be afraid to ask the question that seems dumb and obvious. The vendor may be hoping you don’t!

When you see a vendor's eyes glaze over trying to handle your real data, you'll know the truth.


## Next: How to de-risk with AI co-pilots

Let’s say the sandbox goes well. You’re still not done. You need to see sustained performance to ensure model drift, error rates, and training costs are actually realistic at scale. This is where a limited pilot comes in.

To win here look for internal AI translators—people who understand AI and your business context. They should have deep knowledge of your business processes, speak fluent AI, and have credibility with both technical teams and leadership.

If MD Anderson had involved clinical champions from the start, asking hard questions about treatment logic and workflow fit, the gaps would have been obvious. Instead, they discovered too late that staff found Watson's recommendations confusing or misleading.

The Department of Labor failed because business unit experts didn't drive scenario definition or data validation in procurement.

What if you don’t have a champion and need to hire one? What if that’s not in the budget this year?

I gotta say, if you worry about an AI champion's salary, why aren't you worried about the $1.2 million companies are spending on vendors. Statistically, most of that money is wasted at most companies. It's worth the salary to de-risk your vendor strategy.

No time to hire externally, and no internal champion? If you're spending half a million or more on AI, spending 5-10% on external experts for evaluation makes sense. Both MD Anderson and the Department of Labor would have benefited from independent auditors aligned to their interests but deep on AI.

Once you have a champion or advisor, put them in charge of the pilot and make sure they know exactly what the vendor has claimed so far. It’s their job to push the edges and either validate claims or come back and say “nope, we tried it at scale on real data and it failed.” Make it clear a failure will be respected and in no way considered a black mark on their career. You want your AI champions honest here.


## Putting it all together: the four gates

I want to simplify this for you. A good AI vendor pilot process runs through these four gates. Your AI champion and you and your leadership team should all agree that the vendor passes all four before moving to a signed deal and a partnership.

**Gate One: Business Scenario Proof.** Those three to five tough scenarios—the vendor needs to achieve 80-90% success. If they're only getting two or three out of five right, that's not the right vendor.

**Gate Two: Operations Check.** Define cost and speed requirements in business terms. See through a pilot that they can deliver on actual workload. Have a rollback plan if it doesn't work.

**Gate Three: Risk and Governance Audit.** The vendor must map their solution to your compliance requirements—not theirs, not the model makers, yours. You're accountable, so they're accountable.

**Gate Four: Integration and Change Management.** Define what working in your environment means. Live integration test with your existing systems. This is pass-fail. It either works without custom development as promised, or it doesn't.

Had MD Anderson and the Department of Labor applied these gates, they would have caught their disasters before signing. Watson would have failed Gate One on clinical scenario testing and Gate Four on integration. The unemployment system would have failed Gate Two on operational testing with real claims data.


## Become a buyer, not a victim

MD Anderson lost $62 million. The Department of Labor faced Congressional scrutiny. A Hong Kong bank lost $25 million to deepfakes. They had technical teams, procurement processes, and board oversight. What they didn't have was executive ownership of AI evaluation.

Failed projects mean public losses, internal remediation spend, and reputation damage at the board level. Without discipline upfront, AI projects snowball into repeated consulting and systems rescue costs.

If executives sandboxed, asked hard questions, pushed vendors off their talk track, and didn't delegate this critical purchase—we'd see fewer disasters.

You don't have to become an AI expert overnight, but you do need specific competencies in assessing vendors. Those competencies are learnable. Take the scripts I've given you and use them tomorrow.

These vendors aren't that deep. Put real data in front of them and demand real action. I've seen their eyes glaze over. It's possible to catch them.

No C-suite leader can shield the company from AI risk by delegating the hard questions. Demand live validation, insist on transparency, and hold vendors to each gate—before the board holds you accountable for a $400,000 mistake that could have been prevented.

[![](https://substackcdn.com/image/fetch/$s_!6fQT!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb26138f5-2860-4c2f-8b32-d0c0d8907197_1024x1024.png)](https://substackcdn.com/image/fetch/$s_!6fQT!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb26138f5-2860-4c2f-8b32-d0c0d8907197_1024x1024.png)


# Sources

**1. Zylo 2025 SaaS Management Index**
<https://zylo.com/blog/ai-cost/>
*"AI Pricing: What's the True AI Cost for Businesses in 2025?"* - Primary source for $400K average AI-native app spending and $1.2M enterprise AI budgets, representing 75.2% year-over-year increase.

**2. MIT Media Lab Project NANDA Study**
<https://fortune.com/2025/08/21/an-mit-report-that-95-of-ai-pilots-fail-spooked-investors-but-the-reason-why-those-pilots-failed-is-what-should-make-the-c-suite-anxious/>
*"An MIT report that 95% of AI pilots fail spooked investors..."* - Fortune coverage of preliminary MIT findings showing 95% of GenAI implementations show no measurable P&L impact.

**3. IBM Watson for Oncology Analysis**
<https://digitaldefynd.com/IQ/top-ai-disasters/>
*"Top 30 AI Disasters [Detailed Analysis]"* - Comprehensive analysis of IBM Watson Health's $4B+ failure including MD Anderson's $62M loss and subsequent project shutdown.

**4. Government AI Procurement Challenges**
<https://files.thegovlab.org/a-snapshot-of-ai-procurement-challenges-june2023.pdf>
*"A Snapshot of AI Procurement Challenges"* - GovLab research documenting federal AI procurement failures including Department of Labor unemployment system disasters and integration problems.

**5. AI Implementation Failures in Real-World Deployments**
<https://www.schellman.com/blog/ai-services/ai-implementation-failures-in-real-world-deployments>
*"AI Implementation Failures in Real-World Deployments"* - Cybersecurity firm analysis of enterprise AI deployment failures and common integration problems across industries.

**6. Executive AI Fluency Gap Research**
<https://lanternstudios.com/insights/blog/the-8-problem-and-why-ai-fluency-in-leadership-is-an-urgent-business-priority/>
*"The 8% Problem and Why AI Fluency in Leadership is an Urgent Business Priority"* - Study showing only 8% of leaders feel AI fluent while 88% increase AI budgets.

**7. AI Vendor Evaluation Best Practices**
<https://f7i.ai/blog/the-no-bs-framework-how-to-evaluate-the-ai-capabilities-of-a-vendor-in-2025>
*"How to Evaluate a Vendor's AI Capabilities: The 2025 Guide"* - Technical evaluation framework showing 88% of AI vendors refuse model transparency and common procurement failure points.
